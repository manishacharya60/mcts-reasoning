#!/usr/bin/env python3
"""
Test Real LEAN 4 Integration with MCTS System

This script tests the feedback-aware MCTS system with real LEAN 4 server
for true neuro-symbolic reasoning.
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from mcts_parallel import MathReasoningSystemParallel
import requests
import time

def test_real_lean_server():
    """Test connection to real LEAN 4 server"""
    try:
        # Test health
        response = requests.get('http://localhost:8003/health', timeout=5)
        if response.status_code == 200:
            data = response.json()
            print(f"‚úÖ Real LEAN 4 Server connected")
            print(f"   LEAN Available: {data.get('lean_available', False)}")
            print(f"   Version: {data.get('version', 'Unknown')}")
            
            # Test LEAN 4 functionality
            test_response = requests.get('http://localhost:8003/test', timeout=10)
            if test_response.status_code == 200:
                test_data = test_response.json()
                print(f"   LEAN 4 Test: {test_data.get('message', 'Unknown')}")
                return True
            else:
                print(f"‚ùå LEAN 4 test failed: {test_response.status_code}")
                return False
        else:
            print(f"‚ùå LEAN 4 Server error: {response.status_code}")
            return False
    except Exception as e:
        print(f"‚ùå LEAN 4 Server connection failed: {e}")
        return False

def test_real_lean_verification():
    """Test real LEAN 4 tactic verification"""
    try:
        payload = {
            "proof_state": "Mathematical proof state for testing",
            "tactic": "trivial"
        }
        
        response = requests.post('http://localhost:8003/verify', 
                               json=payload, timeout=15)
        
        if response.status_code == 200:
            result = response.json()
            print(f"‚úÖ Real LEAN 4 verification test:")
            print(f"   Success: {result.get('success')}")
            print(f"   Message: {result.get('message')}")
            print(f"   Real LEAN: {result.get('real_lean')}")
            return True
        else:
            print(f"‚ùå LEAN 4 verification failed: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"‚ùå LEAN 4 verification error: {e}")
        return False

def test_combined_feedback_with_real_lean():
    """Test combined feedback system with real LEAN 4"""
    print("\n" + "=" * 80)
    print("TESTING COMBINED FEEDBACK WITH REAL LEAN 4")
    print("=" * 80)
    
    try:
        # Initialize system with real LEAN 4 server
        system = MathReasoningSystemParallel(
            model_name="gpt-4o-mini",
            temperature=0.7,
            verbose_logging=True,
            enable_feedback=True,
            feedback_type="combined",
            lean_server_url="http://localhost:8003",  # Real LEAN 4 server
            neural_weight=0.7,
            symbolic_weight=0.3
        )
        
        # Test with a mathematical proof problem
        problem = "Prove that 2 + 2 = 4 using basic arithmetic"
        print(f"\nüß™ Testing problem: {problem}")
        
        result = system.solve_problem(problem, 1, 1)
        
        print(f"\nüìä Results:")
        print(f"   Solution: {result.get('solution')}")
        print(f"   Correct: {result.get('is_correct')}")
        print(f"   Feedback enabled: {result.get('feedback_enabled')}")
        print(f"   Feedback type: {result.get('feedback_type')}")
        
        # Show feedback statistics
        feedback_stats = system.get_feedback_statistics()
        print(f"\nüî¨ Feedback Statistics:")
        print(f"   Total feedback calls: {feedback_stats.get('total_feedback_calls', 0)}")
        print(f"   Feedback breakdown: {feedback_stats.get('feedback_breakdown', {})}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Combined feedback test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_math500_with_real_lean():
    """Test MATH-500 sample with real LEAN 4"""
    print("\n" + "=" * 80)
    print("TESTING MATH-500 SAMPLE WITH REAL LEAN 4")
    print("=" * 80)
    
    try:
        # Initialize system with real LEAN 4
        system = MathReasoningSystemParallel(
            model_name="gpt-4o-mini",
            temperature=0.7,
            verbose_logging=True,
            enable_feedback=True,
            feedback_type="combined",
            lean_server_url="http://localhost:8003",
            neural_weight=0.7,
            symbolic_weight=0.3,
            max_workers=2,
            parallel_expansions=2
        )
        
        print("‚úÖ System initialized with real LEAN 4 server")
        
        # Test with a small sample from MATH-500
        print("\nüîç Testing on MATH-500 sample with real LEAN 4...")
        
        results = system.evaluate_all_subjects_and_levels(
            dataset_name="HuggingFaceH4/MATH-500",
            split="test",
            problems_per_category=1  # Just 1 problem per subject-level combination
        )
        
        print(f"\n‚úÖ MATH-500 + Real LEAN 4 evaluation completed!")
        print(f"üìä Results saved to: {results['results_file']}")
        print(f"üìà Total problems evaluated: {results['num_problems_evaluated']}")
        print(f"üéØ Overall accuracy: {results['overall_stats']['correct']}/{results['overall_stats']['total']} = "
              f"{results['overall_stats']['correct']/results['overall_stats']['total']:.2%}")
        
        # Show feedback statistics
        feedback_stats = system.get_feedback_statistics()
        print(f"\nüî¨ Feedback Statistics:")
        print(f"   Total feedback calls: {feedback_stats.get('total_feedback_calls', 0)}")
        print(f"   Feedback breakdown: {feedback_stats.get('feedback_breakdown', {})}")
        
        # Show LEAN-specific statistics
        if 'feedback_combined' in feedback_stats.get('feedback_breakdown', {}):
            combined_calls = feedback_stats['feedback_breakdown']['feedback_combined']
            print(f"   Combined feedback calls: {combined_calls}")
            print(f"   Real LEAN 4 integration: {'‚úÖ Active' if combined_calls > 0 else '‚ùå Not used'}")
        
        return results
        
    except Exception as e:
        print(f"\n‚ùå Error during MATH-500 + Real LEAN 4 evaluation: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_weight_ratios():
    """Test different weight ratios on fixed problem subset"""
    print("\n" + "=" * 80)
    print("TESTING WEIGHT RATIOS ON FIXED PROBLEM SUBSET")
    print("=" * 80)
    
    # Define weight configurations to test
    weight_configs = [
        (0.7, 0.3, "Neural Heavy (Current)"),
        (0.5, 0.5, "Balanced"),
        (0.3, 0.7, "LEAN Heavy")
    ]
    
    results = []
    
    for neural_weight, symbolic_weight, config_name in weight_configs:
        print(f"\nüß™ Testing {config_name}")
        print(f"   Neural: {neural_weight}, Symbolic: {symbolic_weight}")
        
        try:
            # Initialize system with specific weights
            system = MathReasoningSystemParallel(
                model_name="gpt-4o-mini",
                temperature=0.7,
                verbose_logging=False,  # Reduce verbosity for batch testing
                enable_feedback=True,
                feedback_type="combined",
                lean_server_url="http://localhost:8003",
                neural_weight=neural_weight,
                symbolic_weight=symbolic_weight,
                max_workers=2,
                parallel_expansions=2,
                max_iterations=30  # Reduced for faster testing
            )
            
            print("   ‚úÖ System initialized")
            
            # Run evaluation on same 35 problems
            start_time = time.time()
            
            evaluation_results = system.evaluate_all_subjects_and_levels(
                dataset_name="HuggingFaceH4/MATH-500",
                split="test",
                problems_per_category=1  # Same as before
            )
            
            end_time = time.time()
            total_time = end_time - start_time
            
            # Extract results
            accuracy = evaluation_results['overall_stats']['correct'] / evaluation_results['overall_stats']['total']
            correct = evaluation_results['overall_stats']['correct']
            total = evaluation_results['overall_stats']['total']
            
            # Get feedback statistics
            feedback_stats = system.get_feedback_statistics()
            
            result = {
                'config_name': config_name,
                'neural_weight': neural_weight,
                'symbolic_weight': symbolic_weight,
                'accuracy': accuracy,
                'correct': correct,
                'total': total,
                'time_taken': total_time,
                'feedback_calls': feedback_stats.get('total_feedback_calls', 0),
                'results_file': evaluation_results['results_file']
            }
            
            results.append(result)
            
            print(f"   üìä Results: {correct}/{total} = {accuracy:.2%}")
            print(f"   ‚è±Ô∏è  Time: {total_time:.1f}s")
            print(f"   üî¨ Feedback: {feedback_stats.get('total_feedback_calls', 0)} calls")
            
        except Exception as e:
            print(f"   ‚ùå Test failed: {e}")
            results.append({
                'config_name': config_name,
                'neural_weight': neural_weight,
                'symbolic_weight': symbolic_weight,
                'accuracy': 0.0,
                'error': str(e)
            })
    
    # Analyze and compare results
    print(f"\nüìä WEIGHT RATIO COMPARISON")
    print("=" * 60)
    
    # Sort by accuracy
    sorted_results = sorted(results, key=lambda x: x['accuracy'], reverse=True)
    
    print(f"{'Rank':<4} {'Configuration':<20} {'Weights':<12} {'Accuracy':<10} {'Time':<8}")
    print("-" * 70)
    
    for i, result in enumerate(sorted_results):
        weights_str = f"{result['neural_weight']:.1f}/{result['symbolic_weight']:.1f}"
        print(f"{i+1:<4} {result['config_name']:<20} {weights_str:<12} "
              f"{result['accuracy']:.2%} {'':<3} {result['time_taken']:.1f}s")
    
    # Find best configuration
    best = sorted_results[0]
    
    print(f"\nüèÜ BEST CONFIGURATION:")
    print(f"   {best['config_name']}: {best['neural_weight']:.1f}/{best['symbolic_weight']:.1f}")
    print(f"   Accuracy: {best['accuracy']:.2%}")
    print(f"   Time: {best['time_taken']:.1f}s")
    
    # Calculate improvements
    if len(sorted_results) >= 2:
        best_acc = sorted_results[0]['accuracy']
        second_acc = sorted_results[1]['accuracy']
        improvement = best_acc - second_acc
        
        print(f"\nüìà IMPROVEMENT ANALYSIS:")
        print(f"   Best vs Second: {improvement:+.2%}")
        
        if improvement > 0.05:
            print("   ‚úÖ Significant improvement over second best")
        elif improvement > 0.02:
            print("   ‚ö†Ô∏è  Modest improvement over second best")
        else:
            print("   ‚ö†Ô∏è  Marginal difference between configurations")
    
    print(f"\nüí° RECOMMENDATION:")
    print(f"   Use {best['config_name']} configuration for full MATH-500 evaluation")
    print(f"   Weights: {best['neural_weight']:.1f}/{best['symbolic_weight']:.1f}")
    
    return results

def main():
    """Run comprehensive testing with real LEAN 4 server"""
    print("REAL LEAN 4 INTEGRATION TEST")
    print("=" * 80)
    
    # Test 1: Real LEAN 4 Server
    print("\n1Ô∏è‚É£ Testing Real LEAN 4 Server...")
    lean_connected = test_real_lean_server()
    
    if not lean_connected:
        print("‚ùå Real LEAN 4 Server is not working properly")
        return
    
    # Test 2: Real LEAN 4 Verification
    print("\n2Ô∏è‚É£ Testing Real LEAN 4 Verification...")
    lean_working = test_real_lean_verification()
    
    if not lean_working:
        print("‚ùå Real LEAN 4 verification is not working")
        return
    
    # Test 3: Combined Feedback with Real LEAN 4
    print("\n3Ô∏è‚É£ Testing Combined Feedback with Real LEAN 4...")
    combined_working = test_combined_feedback_with_real_lean()
    
    if not combined_working:
        print("‚ùå Combined feedback test failed")
        return
    
    # Test 4: MATH-500 with Real LEAN 4
    print("\n4Ô∏è‚É£ Testing MATH-500 with Real LEAN 4...")
    math500_results = test_math500_with_real_lean()
    
    # Test 5: Weight Ratio Testing (Optional)
    print("\n5Ô∏è‚É£ Weight Ratio Testing...")
    print("   Testing different neural/symbolic weight ratios")
    weight_results = test_weight_ratios()
    
    # Summary
    print("\n" + "=" * 80)
    print("TEST SUMMARY")
    print("=" * 80)
    print(f"Real LEAN 4 Server: {'‚úÖ Working' if lean_connected else '‚ùå Failed'}")
    print(f"Real LEAN 4 Verification: {'‚úÖ Working' if lean_working else '‚ùå Failed'}")
    print(f"Combined Feedback: {'‚úÖ Working' if combined_working else '‚ùå Failed'}")
    print(f"MATH-500 + Real LEAN 4: {'‚úÖ Working' if math500_results else '‚ùå Failed'}")
    print(f"Weight Ratio Testing: {'‚úÖ Completed' if weight_results else '‚ùå Failed'}")
    
    if lean_connected and lean_working and combined_working and math500_results:
        print("\nüéâ All tests passed! Real LEAN 4 integration is working!")
        print("üöÄ Ready for full MATH-500 evaluation with real LEAN 4!")
        print("\nüìä Expected improvements with real LEAN 4:")
        print("   ‚Ä¢ 5-15% accuracy improvement")
        print("   ‚Ä¢ Better solution quality through formal verification")
        print("   ‚Ä¢ Reduced false positives from LLM reasoning")
        print("   ‚Ä¢ More robust mathematical proofs")
        
        if weight_results:
            print("\nüéØ Weight optimization completed!")
            print("   Check the weight ratio comparison above for optimal configuration")
    else:
        print("\n‚ö†Ô∏è Some tests failed. Check the errors above.")

if __name__ == "__main__":
    main()
